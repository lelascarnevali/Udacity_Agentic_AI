# PadrÃµes de Agentic Workflows: Prompt Chaining

---

## 1. Conceito Fundamental

$$
\text{Prompt Chaining} = \text{DecomposiÃ§Ã£o de Tarefas} + \text{Encadeamento de Chamadas LLM}
$$

**DefiniÃ§Ã£o tÃ©cnica:** Prompt chaining Ã© um padrÃ£o de workflow agÃªntico onde uma tarefa complexa Ã© decomposta em uma sequÃªncia de passos menores e mais gerenciÃ¡veis. Cada passo Ã© uma chamada LLM distinta, e a saÃ­da de um passo alimenta diretamente a entrada do prÃ³ximo.

> **Analogia do Mundo Real:** Assim como uma linha de montagem em uma fÃ¡brica divide a construÃ§Ã£o de um carro em estaÃ§Ãµes especializadas (nÃ£o um Ãºnico operÃ¡rio tentando fazer tudo), prompt chaining divide um problema complexo em subtarefas focadas. Cada "trabalhador" (chamada LLM) concentra-se apenas em sua tarefa especÃ­fica.

**Por que usar?**
- ğŸ¯ **Maior Clareza**: Cada chamada LLM Ã© mais simples e direta
- ğŸ”„ **RaciocÃ­nio Aprofundado**: MÃºltiplos passos permitem raciocÃ­nio progressivo
- ğŸ“Š **ReduÃ§Ã£o de AlucinaÃ§Ãµes**: Mantendo o modelo focado em subtarefas
- ğŸ› ï¸ **Debugging Facilitado**: Pontos de falha isolados e bem definidos

---

## 2. Arquitetura & Componentes

### Fluxo BÃ¡sico de Prompt Chaining

```mermaid
flowchart LR
    A["ğŸ“¥ Input<br/>(Tarefa Original)"] --> B["ğŸ”— Passo 1<br/>(LLM Call)"]
    B --> C["âœ… ValidaÃ§Ã£o 1"]
    C -->|Passa| D["ğŸ”— Passo 2<br/>(LLM Call)"]
    C -->|Falha| E["ğŸ”„ Retry/Refine"]
    E --> B
    D --> F["âœ… ValidaÃ§Ã£o 2"]
    F -->|Passa| G["ğŸ”— Passo 3<br/>(LLM Call)"]
    F -->|Falha| E
    G --> H["âœ… ValidaÃ§Ã£o Final"]
    H -->|Passa| I["ğŸ“¤ Output<br/>(Resultado)"]
    H -->|Falha| E
```

### Componentes-Chave

| Componente | Papel | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| ğŸ“¥ **Input** | Tarefa Inicial | A pergunta ou requisiÃ§Ã£o original do usuÃ¡rio |
| ğŸ”— **Passo** | Processamento Sequencial | Uma chamada LLM focada em uma subtarefa |
| âœ… **ValidaÃ§Ã£o** | Controle de Qualidade | Gate que verifica se a saÃ­da estÃ¡ correta antes de passar adiante |
| ğŸ”„ **Tratamento de Erro** | RecuperaÃ§Ã£o | Retry, re-prompt com feedback, ou fallback |
| ğŸ“¤ **Output** | Resultado Final | A resposta consolidada apÃ³s todos os passos |

---

## 3. O Desafio: PropagaÃ§Ã£o de Erros

### Problema

Uma caracterÃ­stica-chave do prompt chaining Ã© que a saÃ­da de um passo alimenta diretamente o prÃ³ximo â€” criando uma **cadeia de dependÃªncias**.

```mermaid
flowchart LR
    A["Passo 1<br/>(Erro âŒ)"] --> B["Passo 2<br/>(Herda erro)"]
    B --> C["Passo 3<br/>(Compondo erro)"]
    C --> D["ğŸ”¥ Falha Total"]

    style A fill:#ffcccc
    style B fill:#ffcccc
    style C fill:#ffcccc
    style D fill:#ff6666
```

**Exemplo Real:**
- Passo 1: AnÃ¡lise de dados financeiros produz valor incorreto
- Passo 2: CÃ¡lculo de juros usa valor errado
- Passo 3: RelatÃ³rio final propaga o erro composto
- **Resultado:** DecisÃµes incorretas baseadas em dados falhos

### SoluÃ§Ã£o: ValidaÃ§Ã£o IntermediÃ¡ria

A resposta Ã© **validaÃ§Ã£o intermediÃ¡ria**: verificar sistematicamente a precisÃ£o, relevÃ¢ncia e formato da saÃ­da de cada passo *antes* de passÃ¡-la adiante.

> **MetÃ¡fora:** Pontos de "controle de qualidade" (gates) na linha de montagem. Cada gate certifica-se de que a saÃ­da intermediÃ¡ria estÃ¡ alinhada com o esperado.

---

## 4. EstratÃ©gias de ValidaÃ§Ã£o

### Quatro Abordagens Principais

| Abordagem | Como Funciona | Melhor Para | Exemplo |
| :--- | :--- | :--- | :--- |
| **ğŸ”§ VerificaÃ§Ãµes ProgramÃ¡ticas** | CÃ³digo customizado testa condiÃ§Ãµes explÃ­citas | Estrutura, formato, limites | JSON vÃ¡lido? Resumo â‰¤ 500 chars? Valor entre 0-100? |
| **ğŸ¤– ValidaÃ§Ã£o por LLM** | Outra chamada LLM avalia a saÃ­da anterior | Qualidades sutis (precisÃ£o, relevÃ¢ncia, tom) | "Este resumo Ã© preciso e relevante?" |
| **ğŸ“ ValidaÃ§Ã£o por Regras** | Regras predefinidas checam padrÃµes esperados | Conformidade com formato | Email tem saudaÃ§Ã£o e fechamento? |
| **ğŸ“Š Confidence Scoring** | Usa scores de confianÃ§a do prÃ³prio LLM | AvaliaÃ§Ã£o rÃ¡pida de incerteza | Score > 0.85? SenÃ£o, retry |

**DecisÃ£o:** Escolha baseado no contexto â€” ou combine estratÃ©gias.

---

## 5. Tratamento de Falhas na ValidaÃ§Ã£o

Quando a validaÃ§Ã£o detecta um problema, temos vÃ¡rias estratÃ©gias:

| EstratÃ©gia | DescriÃ§Ã£o | Quando Usar |
| :--- | :--- | :--- |
| **ğŸ”„ Retry Simples** | Re-executar o passo | Problemas transitÃ³rios de LLM |
| **ğŸ’¬ Re-prompt com Feedback** | Incorporar crÃ­tica da validaÃ§Ã£o na nova prompt | Erros sistemÃ¡ticos ("seu resumo Ã© muito longo") |
| **ğŸ›‘ Fallback** | Encerrar chain ou rotear para caminho alternativo | MÃºltiplas falhas ou edge cases crÃ­ticos |
| **ğŸ¤” Critique & Refine** | LLM critica sua prÃ³pria saÃ­da, depois refina | IteraÃ§Ã£o controlada e transparente |
| **ğŸ“ Logging & Monitoring** | Registrar cada input, output e resultado de validaÃ§Ã£o | Debugging e anÃ¡lise pÃ³s-execuÃ§Ã£o |

---

## 6. Gerenciamento de Contexto

### O Dilema

- **Pouco contexto:** LLM "esquece" detalhes importantes de passos anteriores
- **Muito contexto:** Degrade de performance, excesso de tokens, janela de contexto excedida

### EstratÃ©gias de Balanceamento

#### 1. **Passing Seletivo de Contexto**
Passar *apenas* as partes mais relevantes da saÃ­da anterior.

```python
# âŒ Evite: Passar tudo
def chaining_poor(user_input: str) -> str:
    step1_output = llm_call("Analyze: " + user_input)  # Muito texto
    step2_input = "Use this context: " + step1_output  # Tudo acoplado
    return llm_call(step2_input)

# âœ… FaÃ§a: Extrair apenas o essencial
def chaining_better(user_input: str, llm_call: Callable) -> str:
    step1_output = llm_call(f"Analyze: {user_input}")
    relevant_part = extract_summary(step1_output)  # Extrai essÃªncia
    step2_input = f"Use this finding: {relevant_part}"
    return llm_call(step2_input)
```

#### 2. **Reiteration Contextual**
Re-apresentar detalhes crÃ­ticos em cada nova prompt para evitar esquecimento.

```python
def chaining_with_reiteration(user_input: str, context_rules: str) -> str:
    """A cada passo, relembra o objetivo e regras."""
    step1 = llm_call(f"""
    Objetivo Original: {user_input}
    Regras a Seguir: {context_rules}
    ---
    Tarefa Passo 1: [anÃ¡lise especÃ­fica]
    """)

    step2 = llm_call(f"""
    Objetivo Original: {user_input}
    Regras a Seguir: {context_rules}
    Resultado Passo 1: {step1}
    ---
    Tarefa Passo 2: [aÃ§Ã£o seguinte]
    """)
    return step2
```

---

## 7. Arquitetura de ImplementaÃ§Ã£o

### PadrÃ£o GenÃ©rico: Chain Executor

```python
from typing import Callable, Any, Optional

class ChainStep:
    """Representa um passo na cadeia."""
    def __init__(
        self,
        name: str,
        prompt_template: str,
        validator: Optional[Callable[[str], bool]] = None,
        error_handler: Optional[Callable] = None
    ):
        self.name = name
        self.prompt_template = prompt_template
        self.validator = validator
        self.error_handler = error_handler

class PromptChain:
    """Gerencia execuÃ§Ã£o sequencial de passos com validaÃ§Ã£o."""
    def __init__(self, steps: list[ChainStep]):
        self.steps = steps
        self.execution_log = []

    def execute(self, initial_input: str, llm_call: Callable) -> str:
        """Executa a cadeia com validaÃ§Ã£o e tratamento de erro."""
        context = initial_input

        for step in self.steps:
            # Log inÃ­cio do passo
            self.execution_log.append({
                "step": step.name,
                "input": context,
                "status": "running"
            })

            # Executa prompt
            prompt = step.prompt_template.format(context=context)
            output = llm_call(prompt)

            # Valida output
            if step.validator:
                if not step.validator(output):
                    if step.error_handler:
                        output = step.error_handler(output, context)
                    else:
                        raise ValueError(f"ValidaÃ§Ã£o falhou em {step.name}")

            # Log resultado
            self.execution_log.append({
                "step": step.name,
                "output": output,
                "status": "completed"
            })

            # Contexto para prÃ³ximo passo
            context = output

        return context
```

### Exemplo de Uso

```python
# Define passos com validators
analysis_step = ChainStep(
    name="AnÃ¡lise",
    prompt_template="Analise os dados: {context}",
    validator=lambda x: len(x) > 50  # ValidaÃ§Ã£o simples
)

summary_step = ChainStep(
    name="SumarizaÃ§Ã£o",
    prompt_template="Resuma concisamente: {context}",
    validator=lambda x: 100 < len(x) < 500  # Comprimento esperado
)

# Monta a cadeia
chain = PromptChain([analysis_step, summary_step])

# Executa
result = chain.execute("Dados financeiros Q4", llm_call=call_gpt)
```

---

## 8. Regras de Ouro (Golden Rules)

### âœ… FaÃ§a

1. **Decomponha tarefas em subtarefas atÃ´micas.** Cada LLM call deve responder uma pergunta clara e focada.
2. **Implemente validaÃ§Ã£o apÃ³s cada passo.** NÃ£o deixe erros propagarem.
3. **Use logging extensivo.** Registre inputs, outputs e resultados de validaÃ§Ã£o para debugging.
4. **Passe contexto seletivamente.** Inclua apenas o necessÃ¡rio e suficiente.
5. **Teste estratÃ©gias de erro.** Verifique retry, re-prompting e fallback em casos reais.
6. **Documente dependÃªncias.** Deixe claro qual saÃ­da de um passo alimenta qual entrada do prÃ³ximo.

### âŒ Evite

1. **Cadeias muito longas sem checkpoints.** Risco exponencial de erro.
2. **Validadores muito frouxos.** Erros silenciosos sÃ£o piores que falhas explÃ­citas.
3. **Overloading de contexto.** Passar "tudo" aumenta alucinaÃ§Ãµes.
4. **Retry infinito.** Defina limites e triggers para fallback.
5. **Falta de monitoramento.** Sem logs, Ã© impossÃ­vel saber onde falhou.

---

## 9. Armadilhas Comuns & Debugging

| Armadilha | Sintoma | SoluÃ§Ã£o |
| :--- | :--- | :--- |
| **Erro nÃ£o detectado cedo** | Passo 4 falha porque passo 1 estava errado | Valide agressivamente apÃ³s cada passo |
| **Perda de contexto** | LLM no passo 3 "esqueceu" objetivo original | Use reiteration de contexto crÃ­tico |
| **Contexto excedido** | Token limit atingido no meio da cadeia | Implemente passagem seletiva de contexto |
| **Retry infinito** | Sistema trava tentando corrigir indefinidamente | Defina max_retries e fallback explÃ­cito |
| **Validador muito restritivo** | VÃ¡lidas saÃ­das sÃ£o rejeitadas | Teste validators com exemplos reais |

---

## 10. Resumo & PrÃ³ximos Passos

VocÃª dominou **Prompt Chaining**, um dos padrÃµes mais poderosos de agentic workflows.

### Habilidades Desenvolvidas
âœ… **Task Decomposition** â€” Dividir problemas complexos em subtarefas
âœ… **Sequential Prompting** â€” Estruturar LLM calls que se alimentam
âœ… **Error Prevention & Recovery** â€” ValidaÃ§Ã£o e tratamento de falhas
âœ… **Context Management** â€” Balancear informaÃ§Ã£o vs. performance
âœ… **Implementation & Monitoring** â€” CÃ³digo robusto com logging

### PrÃ³ximas Explorations
- **ParallelizaÃ§Ã£o:** O que fazer quando mÃºltiplas tarefas podem rodar simultaneamente?
- **Agentic Orchestration:** Quando vocÃª quer que o sistema escolha *qual* prompt executar?
- **Tool Integration:** Como integrar APIs e ferramentas em cadeias de prompts?

---

[â† TÃ³pico Anterior: Modelagem de Agentic Workflows](03-agentic-workflow-modeling.md) | [PrÃ³ximo TÃ³pico: PadrÃµes de Agentic Workflows: Routing â†’](05-agentic-workflow-patterns-routing.md)
