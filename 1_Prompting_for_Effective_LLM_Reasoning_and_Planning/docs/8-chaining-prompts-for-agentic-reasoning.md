# Guia de Refer√™ncia: Chaining Prompts para Racioc√≠nio Ag√™ntico

## 1. Conceito Fundamental: Por que Encadear Prompts?

**Limita√ß√µes dos LLMs em Tarefas Complexas:**
- LLMs tradicionais s√£o otimizados para opera√ß√µes simples de entrada-sa√≠da √∫nica
- Opera√ß√µes multi-etapa com depend√™ncias podem causar confus√£o e erros
- Tarefas que requerem dados externos (n√£o presentes no treinamento) necessitam abordagens especiais

**Solu√ß√£o: Prompt Chaining**
Quebrar tarefas complexas em sub-tarefas menores e gerenci√°veis, cada uma com seu pr√≥prio prompt, conectadas programaticamente.

### Analogia
Pedir a um n√£o-padeiro para "assar um bolo de m√∫ltiplas camadas" ‚Üí Falha prov√°vel  
Dar instru√ß√µes passo-a-passo ‚Üí Sucesso mais prov√°vel

---

## 2. Sequential Prompting (Prompting Sequencial)

**Defini√ß√£o:** Racioc√≠nio multi-etapa que quebra uma tarefa complexa em uma s√©rie de sub-tarefas sequenciais.

### Exemplo: LinkedIn Post sobre AI Agents

**‚ùå Abordagem √önica (Problema):**
```
"Pesquise agentes de IA, resuma os conceitos-chave e escreva um post no LinkedIn sobre eles."
```

**‚úÖ Abordagem Sequencial (Solu√ß√£o):**
```
Prompt 1: "Pesquise conceitos-chave de agentes de IA."
         ‚Üí RESPONSE_1

Prompt 2: "Resuma a seguinte informa√ß√£o: {RESPONSE_1}"
         ‚Üí RESPONSE_2

Prompt 3: "Escreva um post no LinkedIn baseado neste resumo: {RESPONSE_2}"
         ‚Üí FINAL_RESPONSE
```

### Benef√≠cios
- ‚úÖ Espelha resolu√ß√£o de problemas humana
- ‚úÖ Permite itera√ß√£o e melhoria individual de cada prompt
- ‚úÖ Melhora precis√£o ao focar em uma meta por vez
- ‚úÖ Facilita debugging e manuten√ß√£o

---

## 3. Prompt Chaining (Encadeamento de Prompts)

**Defini√ß√£o:** Conex√£o program√°tica de prompts onde a sa√≠da de uma chamada LLM se torna entrada da pr√≥xima.

### Estrutura B√°sica
```python
# Chamada 1: Pesquisa
RESPONSE_1 = call_llm("Pesquise conceitos-chave de agentes de IA.")

# Chamada 2: Resumo
prompt_2 = f"Resuma os seguintes conceitos: {RESPONSE_1}"
RESPONSE_2 = call_llm(prompt_2)

# Chamada 3: Draft
prompt_3 = f"Escreva um post no LinkedIn baseado neste resumo: {RESPONSE_2}"
FINAL_RESPONSE = call_llm(prompt_3)
```

### Exemplo Pr√°tico: Consulta de Calend√°rio

**Workflow Hard-coded:**
1. LLM determina se precisa de dados do calend√°rio
   - Input: "Esta consulta requer dados do calend√°rio? QUERY: Que horas √© meu dentista amanh√£?"
   - Output: "Sim"
2. Se "Sim", orquestrador chama `get_calendar()`
3. LLM usa dados do calend√°rio para responder
   - Input: `{calendar_data}`
   - Output: "Seu dentista √© √†s 9h."

**Workflow Ag√™ntico (ReAct Framework):**
```
User: "Que horas √© meu dentista amanh√£?"

LLM: THOUGHT: Preciso chamar get_calendar.
     ACTION: get_calendar("tomorrow")

Orchestrator: Executa get_calendar() ‚Üí {"9am"}

LLM: OBSERVATION: {"9am"}
     THOUGHT: √â √†s 9am. Retornar resposta final.
     ACTION: final_answer("9am")
```

---

## 4. Output Validation: Gate Checks

**Problema:** LLMs podem alucinar, produzir formatos incorretos ou falhar em seguir instru√ß√µes. Um erro em uma etapa inicial pode comprometer todo o processo (efeito domin√≥).

**Solu√ß√£o:** Gate Checks s√£o valida√ß√µes program√°ticas colocadas entre etapas de uma cadeia.

### Fluxo de Decis√£o
```
output = call_llm(prompt_step1)
    ‚Üì
Gate Check: Valida√ß√£o
    ‚Üì
‚úÖ PASS ‚Üí Continue para pr√≥xima etapa
‚ùå FAIL ‚Üí Erro/Retry/Retry com feedback
```

### Tipos de Gate Checks

#### 1. **Format Checks (Verifica√ß√£o de Formato)**
- Estrutura (JSON, XML)
- Comprimento
- Campos obrigat√≥rios
- **Ferramentas:** Pydantic, structured outputs

#### 2. **Content Checks (Verifica√ß√£o de Conte√∫do)**
- Keywords e frases espec√≠ficas
- T√≥picos e relev√¢ncia
- **Ferramentas:** Regex, embeddings sem√¢nticos, outros LLMs

#### 3. **Logic Checks (Verifica√ß√£o de L√≥gica)**
- Sentido num√©rico/l√≥gico
- Para c√≥digo: compila? Importa bibliotecas restritas? Valores num√©ricos razo√°veis?
- **Ferramentas:** AST parsing, linters, execu√ß√£o sandbox

### Pseudo-c√≥digo
```python
output = call_llm(prompt_step1)

if validate_output(output):
    next_input = process(output)
    call_llm(prompt_step2, next_input)
else:
    handle_error(output)
    # Op√ß√µes: raise error, retry, retry com feedback
```

### Estrat√©gias de Falha
1. **Halt:** Parar execu√ß√£o e reportar erro
2. **Retry:** Tentar novamente com mesmo prompt
3. **Feedback Loop:** Tentar novamente incluindo motivo da falha no prompt

---

## 5. Caso de Uso: Gera√ß√£o de Script de An√°lise de Dados

**Tarefa:** Criar script Python para ler CSV, calcular m√©dia de coluna e escrever resultados em novo CSV.

### Cadeia Completa

#### **Step 1: Gerar Outline**
```
Prompt: "Voc√™ √© um assistente de programa√ß√£o √∫til. Preciso de um script 
Python para ler um CSV, calcular a m√©dia de uma coluna e escrever os 
resultados em um novo CSV. Forne√ßa um outline passo-a-passo simples."

Expected Output: Lista numerada ou com bullets de passos de alto n√≠vel

Gate Check 1 (Opcional): Verifica√ß√£o program√°tica de formato de lista
                        e frases-chave como "read", "process", "write"
```

#### **Step 2: Gerar C√≥digo**
```
Prompt: "Baseado no seguinte outline, escreva o c√≥digo Python. 
Use bibliotecas padr√£o como 'csv' e 'statistics'.
Outline: [Inserir Output do Step 1]"

Expected Output: C√≥digo Python

Gate Check 2: Validar sintaxe do c√≥digo
              Implementa√ß√£o: ast.parse() ou linters (flake8, pylint)
              Resultado: Se falhar, parar ou ir para refinamento
```

#### **Step 3: Refinar C√≥digo (Se Gate Check 2 Falhou)**
```
Prompt: "O seguinte c√≥digo Python cont√©m erros de sintaxe:
[Inserir C√≥digo do Step 2]
Feedback de erro: [Inserir Mensagens do Gate Check 2]
Corrija o c√≥digo baseado neste feedback."

Expected Output: C√≥digo Python corrigido

Retry Gate Check 2: Se passar, prosseguir
                   Se falhar, desistir ou loop (m√°x. itera√ß√µes)
```

### Diagrama de Fluxo
```
Prompt 1: Create Outline
    ‚Üì
Gate Check 1 (Formatting)
    ‚Üì
Prompt 2: Write Code
    ‚Üì
Gate Check 2 (Check syntax)
    ‚Üì
‚ùå FAIL ‚Üí Prompt 3: Refinement ‚Üí Gate Check 2
‚úÖ PASS ‚Üí Completed!
```

### Implementa√ß√£o em Python
```python
import ast
from typing import Tuple, Callable

def validate_syntax(code: str) -> Tuple[bool, str]:
    """Valida sintaxe Python usando AST."""
    try:
        ast.parse(code)
        return True, ""
    except SyntaxError as e:
        return False, str(e)

def chain_with_validation(
    prompts: list[str],
    validators: list[Callable],
    llm_call: Callable,
    max_retries: int = 2
) -> str:
    """Executa cadeia de prompts com valida√ß√£o entre etapas."""
    result = None
    
    for i, (prompt, validator) in enumerate(zip(prompts, validators)):
        # Primeira chamada ou usar resultado anterior
        if result:
            prompt = prompt.format(previous_output=result)
        
        result = llm_call(prompt)
        
        # Validar output
        is_valid, error = validator(result)
        retry_count = 0
        
        while not is_valid and retry_count < max_retries:
            feedback_prompt = f"""Previous output had issues:
            {result}
            
            Error: {error}
            
            Please correct and try again."""
            
            result = llm_call(feedback_prompt)
            is_valid, error = validator(result)
            retry_count += 1
        
        if not is_valid:
            raise ValueError(f"Step {i+1} failed after {max_retries} retries")
    
    return result

# Exemplo de uso
def simple_validator(output: str) -> Tuple[bool, str]:
    """Validador simples de exemplo."""
    if len(output) > 10:
        return True, ""
    return False, "Output too short"
```

---

## 6. Melhores Pr√°ticas

### ‚úÖ DO's
- **Decomponha tarefas complexas** em sub-tarefas focadas
- **Use prompts especializados** para cada etapa
- **Implemente gate checks** em pontos cr√≠ticos
- **Forne√ßa feedback** nas tentativas de retry
- **Limite itera√ß√µes** para evitar loops infinitos
- **Log todas as etapas** para debugging e auditoria

### ‚ùå DON'Ts
- N√£o crie prompts √∫nicos gigantes para tarefas multi-etapa
- N√£o assuma que outputs est√£o sempre corretos
- N√£o ignore erros de etapas anteriores
- N√£o encadeie sem valida√ß√£o em aplica√ß√µes cr√≠ticas
- N√£o esque√ßa de tratar casos de falha

---

## 7. Padr√µes Comuns de Cadeia

### Pattern 1: Linear Chain
```
Task ‚Üí Subtask 1 ‚Üí Subtask 2 ‚Üí Subtask 3 ‚Üí Result
```

### Pattern 2: Conditional Chain
```
Task ‚Üí Decision Point ‚Üí Branch A / Branch B ‚Üí Result
```

### Pattern 3: Iterative Refinement
```
Task ‚Üí Generate ‚Üí Validate ‚Üí [If fail: Refine ‚Üí Validate] ‚Üí Result
```

### Pattern 4: Parallel Processing
```
Task ‚Üí Subtask 1 \
       Subtask 2  ‚Üí Merge ‚Üí Result
       Subtask 3 /
```

---

## 8. Aplica√ß√µes no Mundo Real

### Healthcare: Processamento de Registros M√©dicos
```
1. Extract patient data ‚Üí Gate Check (PHI compliance)
2. Summarize findings ‚Üí Gate Check (medical accuracy)
3. Generate report ‚Üí Gate Check (format validation)
```

### Content Generation: Marketing Copy
```
1. Research topic ‚Üí Gate Check (relevance)
2. Create outline ‚Üí Gate Check (structure)
3. Write draft ‚Üí Gate Check (brand guidelines)
4. Optimize SEO ‚Üí Gate Check (keyword density)
```

### Code Generation & Debugging
```
1. Understand requirements ‚Üí Gate Check (clarity)
2. Generate code ‚Üí Gate Check (syntax)
3. Write tests ‚Üí Gate Check (coverage)
4. Debug errors ‚Üí Gate Check (all tests pass)
```

### Claims Triage (Seguros)
```
1. Extract claim data ‚Üí Gate Check (required fields)
2. Classify urgency ‚Üí Gate Check (policy rules)
3. Route to adjuster ‚Üí Gate Check (assignment rules)
```

---

## 9. Compara√ß√£o: Single Prompt vs. Prompt Chain

| Aspecto | Single Prompt | Prompt Chain |
|:---|:---|:---|
| **Complexidade** | Tarefas simples | Tarefas multi-etapa |
| **Controle** | Baixo | Alto (valida√ß√£o por etapa) |
| **Debugging** | Dif√≠cil | F√°cil (isolar etapa com problema) |
| **Confiabilidade** | Vari√°vel | Alta (com gate checks) |
| **Manuten√ß√£o** | Dif√≠cil modificar | F√°cil (prompts modulares) |
| **Custo** | Baixo | M√©dio-Alto (m√∫ltiplas chamadas) |
| **Lat√™ncia** | Baixa | M√©dia-Alta (sequencial) |

---

## 10. Considera√ß√µes de Implementa√ß√£o

### Gerenciamento de Estado
- Manter contexto entre etapas
- Persistir resultados intermedi√°rios
- Implementar rollback em caso de falha

### Performance
- Considerar custo de m√∫ltiplas chamadas LLM
- Otimizar prompts para reduzir tokens
- Implementar cache quando poss√≠vel

### Escalabilidade
- Paralelizar etapas independentes
- Usar filas para processar cadeias longas
- Implementar rate limiting

### Monitoramento
- Log de cada etapa e gate check
- M√©tricas de sucesso/falha por etapa
- Alertas para falhas recorrentes

---

## 11. Ferramentas e Frameworks

### Bibliotecas Python
- **LangChain:** Framework completo para prompt chaining
- **Pydantic:** Valida√ß√£o de estruturas de dados
- **AST:** Parsing e valida√ß√£o de c√≥digo Python
- **Flake8/Pylint:** Linters para code validation

### Padr√µes de Orquestra√ß√£o
- **Orchestration Layer:** Gerencia fluxo de execu√ß√£o
- **State Machine:** Controla transi√ß√µes entre etapas
- **Event-Driven:** Reage a outputs de etapas anteriores

---

## 12. Recap: Conceitos-Chave

‚úÖ **Task Decomposition:** Problemas complexos devem ser quebrados em sub-tarefas focadas

‚úÖ **Prompt Chaining:** Output de uma instru√ß√£o AI torna-se input da pr√≥xima programaticamente

‚úÖ **Output Validation:** Gate checks s√£o cr√≠ticos para confiabilidade e prevenir propaga√ß√£o de erros

‚úÖ **Stage-Specific Prompting:** Usar prompts distintos e especializados para cada parte melhora precis√£o

‚úÖ **Feedback Loops:** Incluir motivos de falha em retries melhora taxa de sucesso

---

## 13. F√≥rmulas e Equa√ß√µes

### Taxa de Sucesso da Cadeia
$$P_{chain} = \prod_{i=1}^{n} P_i$$

Onde $P_i$ √© a probabilidade de sucesso da etapa $i$.

**Implica√ß√£o:** Uma cadeia de 5 etapas com 90% de sucesso cada = $0.9^5 = 59\%$ de sucesso total.  
**Solu√ß√£o:** Gate checks aumentam $P_i$ individual.

### Custo de Retry com Feedback
$$C_{total} = C_{base} + \sum_{i=1}^{r} (C_{retry} + C_{validation})$$

Onde:
- $C_{base}$: custo da execu√ß√£o inicial
- $r$: n√∫mero de retries
- $C_{retry}$: custo de cada retry
- $C_{validation}$: custo de cada gate check

---

## Recursos Adicionais

### Leitura Recomendada
- [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
- [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903)
- [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)

### Frameworks
- [LangChain Documentation](https://python.langchain.com/)
- [LlamaIndex](https://docs.llamaindex.ai/)
- [Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/)

---

**Parab√©ns por dominar Chaining Prompts para Racioc√≠nio Ag√™ntico!** Esta √© uma habilidade fundamental para construir agentes de IA confi√°veis e capazes. Continue praticando a decomposi√ß√£o de tarefas, implementa√ß√£o de valida√ß√µes e itera√ß√£o de prompts. üöÄ
